{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be06add0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), \"src\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8359dc47-84f5-413e-81d4-62a82c5f7651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import scipy as stats\n",
    "from scipy.stats import chi2\n",
    "from utils import *\n",
    "from siamese import *\n",
    "from data_analysis import *\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "plt.ioff()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75db8f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.path.dirname(os.getcwd())\n",
    "data_path = os.path.join(root_path, \"data/multi_classed_grouped_data\")\n",
    "products = os.listdir(data_path)\n",
    "visualize = True\n",
    "generate_embeddings = False\n",
    "\n",
    "\n",
    "for backbone in [\"resnet18\", \"resnet34\", \"resnet50\", \"wide_resnet\", \"vgg\"]:\n",
    "    print(\n",
    "        \"---------------------------------------------- \"\n",
    "        + backbone\n",
    "        + \" ----------------------------------------------\"\n",
    "    )\n",
    "    for product in products:\n",
    "        print(\n",
    "            \"----------------------------------- \"\n",
    "            + product\n",
    "            + \" -----------------------------------\"\n",
    "        )\n",
    "        # Load corresponding Siamese weights\n",
    "        model_path = os.path.join(\n",
    "            root_path,\n",
    "            \"models\",\n",
    "            product + \"_siamese_\" + backbone + \"_subclass_sampling.pth\",\n",
    "        )\n",
    "        if not os.path.exists(model_path):\n",
    "            print(\"No model for this backbone\")\n",
    "            continue\n",
    "        print(model_path)\n",
    "        if backbone in [\"wide_resnet\", \"vgg11\"]:\n",
    "            device = \"cpu\"\n",
    "\n",
    "        # Load data dicts\n",
    "        product_path = os.path.join(data_path, product)\n",
    "        json_path = os.path.join(\n",
    "            root_path, \"data/augmented_train_test_split\", product)\n",
    "        train_dict = json.load(\n",
    "            open(os.path.join(json_path, product + \"_train_dict.json\"), \"r\")\n",
    "        )\n",
    "        test_dict = json.load(\n",
    "            open(os.path.join(json_path, product + \"_test_dict.json\"), \"r\")\n",
    "        )\n",
    "\n",
    "        # Load data informations\n",
    "        good_images_path = [\n",
    "            image_path for image_path, label in train_dict.items() if label == 1\n",
    "        ]\n",
    "\n",
    "        # Load the embeddings and the list of id\n",
    "        if generate_embeddings:\n",
    "            product_embeddings, all_idx = map_good_train_samples_to_embeddings(\n",
    "                json_path, train_dict, save=True\n",
    "            )\n",
    "        else:\n",
    "            score_path = os.path.join(json_path, \"good_embeddings.csv\")\n",
    "            product_embeddings = np.loadtxt(score_path, delimiter=\",\")\n",
    "            all_idx = np.loadtxt(score_path[:-4] + \"_id.csv\", delimiter=\",\")\n",
    "        product_embeddings_dict = dict(zip(all_idx, product_embeddings))\n",
    "\n",
    "        # Prepare embedding model for test data\n",
    "        embedding_model = torchvision.models.resnet50(\n",
    "            weights=\"ResNet50_Weights.DEFAULT\"\n",
    "        )\n",
    "        modules = list(embedding_model.children())[:-1]\n",
    "        embedding_model = nn.Sequential(*modules)\n",
    "        for p in embedding_model.parameters():\n",
    "            p.requires_grad = False\n",
    "\n",
    "        # Load data to model\n",
    "        transform = transforms.Compose(\n",
    "            [transforms.ToTensor(), transforms.Resize((1024, 1024), antialias=True)]\n",
    "        )\n",
    "\n",
    "        all_score = []\n",
    "        i = 0\n",
    "        # Embed the each test image and find its corresponding model images\n",
    "        for image_path in tqdm(list(test_dict.keys())):\n",
    "            image_dict = {image_path: test_dict[image_path]}\n",
    "\n",
    "            # Load the test images to data loader\n",
    "            embedding_dataset = EmbeddingDataset(\n",
    "                image_dict, transform=transform)\n",
    "            embedding_dataloader = DataLoader(\n",
    "                embedding_dataset, batch_size=1, shuffle=True\n",
    "            )\n",
    "\n",
    "            # Calculate embedding:\n",
    "            for data, _ in embedding_dataloader:\n",
    "                data = data\n",
    "                embedding = embedding_model(data)\n",
    "            embedding = embedding.squeeze().detach().cpu().numpy()\n",
    "\n",
    "            # Find the candidate model images based on embedding distance:\n",
    "            top_embeddings = dict(\n",
    "                sorted(\n",
    "                    product_embeddings_dict.items(),\n",
    "                    key=lambda x: distance(embedding, x[1]),\n",
    "                )\n",
    "            )  # Test Mahalanobis distance, check TSNE juan chua\n",
    "\n",
    "            # Return the dictionary where each key is the test image path and each value are the model images\n",
    "            candidate_id_list = list(top_embeddings.keys())[:1]\n",
    "            candidate_paths = [\n",
    "                good_images_path[int(i)] for i in candidate_id_list]\n",
    "            model_image_dict = dict(\n",
    "                zip(candidate_paths, [1] * len(candidate_paths)))\n",
    "\n",
    "            # Load the test image to the Siamese dataloader\n",
    "            test_dataset = ProductDataset(image_dict, transform=transform)\n",
    "            test_dataloader = DataLoader(\n",
    "                test_dataset, batch_size=1, shuffle=True)\n",
    "            test_image, _, test_label, _ = next(iter(test_dataloader))\n",
    "            test_label = test_label[0, 0]\n",
    "\n",
    "            # Perform similarity score assessment with Siamese model\n",
    "            all_distance = []\n",
    "            # Load Siamese model\n",
    "            n_classes = len(np.unique(list(train_dict.values())))\n",
    "            model = SiameseNetwork(backbone=backbone)\n",
    "            transform = transforms.Compose(\n",
    "                [transforms.ToTensor(), transforms.Resize(\n",
    "                    (512, 512), antialias=True)]\n",
    "            )\n",
    "\n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "            model.eval()\n",
    "            model.to(device)\n",
    "            # Calculate distance from image to all model images\n",
    "            for candidate_path in candidate_paths:\n",
    "                model_image_dict = {candidate_path: 1}\n",
    "                model_dataset = ProductDataset(\n",
    "                    model_image_dict, transform=transform)\n",
    "                model_dataloader = DataLoader(\n",
    "                    model_dataset, batch_size=1, shuffle=True)\n",
    "\n",
    "                model_image, _, model_label, _ = next(iter(model_dataloader))\n",
    "                model_label = model_label[0, 0]\n",
    "                # print(model_label, test_label)\n",
    "\n",
    "                output_1, output_2 = model(\n",
    "                    model_image.to(device), test_image.to(device)\n",
    "                )\n",
    "                euclidean_distance = F.pairwise_distance(\n",
    "                    output_1, output_2, keepdim=True\n",
    "                )\n",
    "\n",
    "                all_distance.append(euclidean_distance.item())\n",
    "\n",
    "            # Save some pairs of images as visualization\n",
    "            if i % 5 == 0:\n",
    "                # Save inference figure\n",
    "                model_image = np.array(\n",
    "                    model_image[0].permute(1, 2, 0) * 255, dtype=np.uint8\n",
    "                )\n",
    "                test_image = np.array(\n",
    "                    test_image[0].permute(1, 2, 0) * 255, dtype=np.uint8\n",
    "                )\n",
    "                label_1 = \"good\"\n",
    "                label_2 = \"defect\" if test_label.numpy() == 0 else \"good\"\n",
    "                label = \"same class\" if label_1 == label_2 else \"different class\"\n",
    "                fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "                ax[0].imshow(model_image[:, :, ::-1])\n",
    "                ax[0].set_xlabel(label_1, weight=\"bold\", fontsize=20)\n",
    "                # ax[0].axis('off')\n",
    "                ax[1].imshow(test_image[:, :, ::-1])\n",
    "                ax[1].set_xlabel(label_2, weight=\"bold\", fontsize=20)\n",
    "                # ax[1].axis('off')\n",
    "                fig.suptitle(\"Dissimilarity score: \" +\n",
    "                             str(euclidean_distance.item()))\n",
    "                figure_name = (\n",
    "                    product\n",
    "                    + \"_siamese_\"\n",
    "                    + backbone\n",
    "                    + \"_visualize_\"\n",
    "                    + str(i)\n",
    "                    + \"_embedded_scoring.png\"\n",
    "                )\n",
    "                figure_path = os.path.join(\n",
    "                    root_path, \"Figure/visualize_inference/embedded_scoring\", product\n",
    "                )\n",
    "                if not os.path.exists(figure_path):\n",
    "                    os.mkdir(figure_path)\n",
    "                figure_path = os.path.join(figure_path, figure_name)\n",
    "                fig.savefig(figure_path)\n",
    "\n",
    "                # Save scatter plot\n",
    "                chosen_id = candidate_id_list[0]\n",
    "                label_list = [\n",
    "                    1 if id != chosen_id else 2 for id in product_embeddings_dict.keys()\n",
    "                ]\n",
    "                label_list.append(3)\n",
    "                label_name_dict = {1: \"good\",\n",
    "                                   2: \"chosen_good\", 3: \"test_image\"}\n",
    "                label_name = [label_name_dict[label] for label in label_list]\n",
    "                # print(np.unique(label_dict))\n",
    "\n",
    "                embedding_list = list(product_embeddings_dict.values())\n",
    "                embedding_list.append(embedding)\n",
    "                embedding_list = np.array(embedding_list)\n",
    "                # print(embedding_list.shape)\n",
    "                embedder = TSNE(2)\n",
    "                embedding_list = embedder.fit_transform(embedding_list)\n",
    "                # print(embedding_list.shape)\n",
    "\n",
    "                fig, ax = plt.subplots()\n",
    "                scatter = ax.scatter(\n",
    "                    embedding_list[:, 0],\n",
    "                    embedding_list[:, 1],\n",
    "                    c=label_list,\n",
    "                    label=label_name,\n",
    "                )\n",
    "                ax.legend(\n",
    "                    handles=scatter.legend_elements()[0],\n",
    "                    labels=list(label_name_dict.values()),\n",
    "                )  # , loc='upper right')\n",
    "                fig.savefig(figure_path[:-4] + \"_scatter_plot.png\")\n",
    "\n",
    "            # Calculate average distance between the test sample and all reference images\n",
    "            avg_distance = np.mean(all_distance)\n",
    "            # Keep track of all such distance\n",
    "            all_score.append(\n",
    "                np.array([1, int(test_label), 1 ==\n",
    "                         int(test_label), avg_distance])\n",
    "            )\n",
    "            # print(avg_distance)\n",
    "            i += 1\n",
    "        # Save the results of all scores to file\n",
    "        result = np.array(all_score)\n",
    "        score_path = os.path.join(\n",
    "            root_path,\n",
    "            \"result/similarity_scores\",\n",
    "            product + \"_siamese_\" + backbone + \"_avg_distance.csv\",\n",
    "        )\n",
    "        np.savetxt(score_path, result, delimiter=\",\")\n",
    "\n",
    "        same_class = result[:, 2]\n",
    "        if len(np.unique(same_class)) != 2:\n",
    "            print(np.unique(same_class))\n",
    "        similarity_scores = result[:, 3]\n",
    "\n",
    "        # # Visualize similarity score histogram\n",
    "        # dissimillar_idx = np.where(same_class == 0.)\n",
    "        # dissimillar_score = similarity_scores[dissimillar_idx]\n",
    "        # simillar_idx = np.where(same_class == 1.)\n",
    "        # simillar_score = similarity_scores[simillar_idx]\n",
    "        # #print(dissimillar_idx, simillar_idx)\n",
    "        # #print(dissimillar_score, simillar_score)\n",
    "        # fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "        # ax[0].hist(simillar_score, edgecolor='black',)\n",
    "        #            #bins=np.arange(simillar_score.min(), simillar_score.max(), 0.1))\n",
    "        # ax[0].set_xlabel('Distance', fontsize = 10)\n",
    "        # ax[0].set_ylabel('Number of instance', fontsize = 10)\n",
    "        # ax[0].set_title(product + ': Similarity score distribution for images for GOOD class')\n",
    "        # ax[1].hist(dissimillar_score, edgecolor='black',)\n",
    "        #            #bins=np.arange(dissimillar_score.min(),dissimillar_score.max(), 0.1))\n",
    "        # ax[1].set_xlabel('Distance', fontsize = 10)\n",
    "        # ax[1].set_ylabel('Number of instance', fontsize = 10)\n",
    "        # ax[1].set_title(product + ': Similarity score distribution for images for DEFECT class')\n",
    "        # fig.show()\n",
    "\n",
    "        # figure_name = product + '_siamese_' + backbone + '_similarity_score_distribution' + '_embedded_scoring.png'\n",
    "        # figure_path = os.path.join(root_path,\n",
    "        #         'Figure/embedded_similarity_score_histogram/' + figure_name)\n",
    "        # fig.savefig(figure_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8359dc47-84f5-413e-81d4-62a82c5f7651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import scipy as stats \n",
    "from scipy.stats import chi2 \n",
    "from utils import *\n",
    "from siamese import *\n",
    "from visualize_attributes import *\n",
    "from sklearn.manifold import TSNE\n",
    "plt.ioff()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75db8f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------- resnet18 ----------------------------------------------\n",
      "----------------------------------- bottle -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/bottle_siamese_resnet18_subclass_sampling.pth\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: \"/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/data/augmentedtrain_test_split/bottle/bottle_train_dict.json\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 24\u001b[0m\n\u001b[1;32m     22\u001b[0m product_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_path, product)\n\u001b[1;32m     23\u001b[0m json_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(root_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/augmentedtrain_test_split\u001b[39m\u001b[38;5;124m'\u001b[39m, product)\n\u001b[0;32m---> 24\u001b[0m train_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_train_dict.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     25\u001b[0m test_dict \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(json_path, product \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_test_dict.json\u001b[39m\u001b[38;5;124m'\u001b[39m), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Load data informations\u001b[39;00m\n",
      "File \u001b[0;32m~/Projects/Course/similarity_venv/lib/python3.8/site-packages/IPython/core/interactiveshell.py:284\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    281\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    282\u001b[0m     )\n\u001b[0;32m--> 284\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: \"/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/data/augmentedtrain_test_split/bottle/bottle_train_dict.json\""
     ]
    }
   ],
   "source": [
    "root_path = os.path.dirname(os.getcwd())\n",
    "data_path = os.path.join(root_path, \"data/multi_classed_grouped_data\")\n",
    "products = os.listdir(data_path)\n",
    "visualize = True\n",
    "generate_embeddings = False\n",
    "\n",
    "\n",
    "for backbone in ['resnet18', 'resnet34', 'resnet50', 'wide_resnet', 'vgg']:\n",
    "    print('---------------------------------------------- ' + backbone + ' ----------------------------------------------')    \n",
    "    for product in products:\n",
    "        print('----------------------------------- ' + product + ' -----------------------------------')\n",
    "        # Load corresponding Siamese weights\n",
    "        model_path = os.path.join(root_path, 'models', product + '_siamese_' + backbone + '_subclass_sampling.pth')\n",
    "        if not os.path.exists(model_path):\n",
    "            print('No model for this backbone')\n",
    "            continue\n",
    "        print(model_path)\n",
    "        if backbone in ['wide_resnet', 'vgg11']:\n",
    "            device = 'cpu'\n",
    "\n",
    "        # Load data dicts\n",
    "        product_path = os.path.join(data_path, product)\n",
    "        json_path = os.path.join(root_path, 'data/augmented_train_test_split', product)\n",
    "        train_dict = json.load(open(os.path.join(json_path, product + '_train_dict.json'), 'r'))\n",
    "        test_dict = json.load(open(os.path.join(json_path, product + '_test_dict.json'), 'r'))\n",
    "\n",
    "        # Load data informations\n",
    "        good_images_path = [image_path for image_path, label in train_dict.items()\n",
    "                            if label == 1]\n",
    "\n",
    "\n",
    "        # Load the embeddings and the list of id\n",
    "        if generate_embeddings:\n",
    "            product_embeddings, all_idx = map_good_train_samples_to_embeddings(json_path, train_dict, save=True)\n",
    "        else:\n",
    "            score_path = os.path.join(json_path, 'good_embeddings.csv')\n",
    "            product_embeddings =  np.loadtxt(score_path, delimiter=\",\")\n",
    "            all_idx = np.loadtxt(score_path[:-4] + '_id.csv', delimiter=\",\")\n",
    "        product_embeddings_dict = dict(zip(all_idx, product_embeddings))\n",
    "\n",
    "        # Prepare embedding model for test data\n",
    "        embedding_model = torchvision.models.resnet50(weights='ResNet50_Weights.DEFAULT')\n",
    "        modules=list(embedding_model.children())[:-1]\n",
    "        embedding_model=nn.Sequential(*modules)\n",
    "        for p in embedding_model.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        # Load data to model\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Resize((1024,1024), antialias=True)])\n",
    "        \n",
    "        all_score = []\n",
    "        i = 0\n",
    "        # Embed the each test image and find its corresponding model images\n",
    "        for image_path in tqdm(list(test_dict.keys())):\n",
    "            image_dict = {image_path: test_dict[image_path]}\n",
    "\n",
    "            # Load the test images to data loader\n",
    "            embedding_dataset = EmbeddingDataset(image_dict, transform=transform)\n",
    "            embedding_dataloader = DataLoader(embedding_dataset, batch_size=1, shuffle=True)\n",
    "        \n",
    "            # Calculate embedding:\n",
    "            for data, _ in embedding_dataloader:\n",
    "                data = data\n",
    "                embedding = embedding_model(data)\n",
    "            embedding = embedding.squeeze().detach().cpu().numpy()\n",
    "\n",
    "            # Find the candidate model images based on embedding distance:\n",
    "            top_embeddings = dict(sorted(product_embeddings_dict.items(), \n",
    "                                    key=lambda x: distance(embedding, x[1]))) # Test Mahalanobis distance, check TSNE juan chua \n",
    "            \n",
    "            # Return the dictionary where each key is the test image path and each value are the model images\n",
    "            candidate_id_list = list(top_embeddings.keys())[:1]\n",
    "            candidate_paths = [good_images_path[int(i)] for i in candidate_id_list]\n",
    "            model_image_dict = dict(zip(candidate_paths, [1]*len(candidate_paths)))\n",
    "\n",
    "            # Load the test image to the Siamese dataloader\n",
    "            test_dataset = ProductDataset(image_dict, transform=transform)\n",
    "            test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "            test_image, _, test_label, _ = next(iter(test_dataloader))\n",
    "            test_label = test_label[0, 0]\n",
    "            \n",
    "            # Perform similarity score assessment with Siamese model\n",
    "            all_distance = []\n",
    "            # Load Siamese model\n",
    "            n_classes = len(np.unique(list(train_dict.values())))\n",
    "            model = SiameseNetwork(n_classes, backbone=backbone)\n",
    "            transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Resize((1024,1024), antialias=True)\n",
    "                                        ])\n",
    "            \n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "            model.eval()\n",
    "            model.to(device)\n",
    "            # Calculate distance from image to all model images\n",
    "            for candidate_path in candidate_paths:\n",
    "                model_image_dict = {candidate_path : 1}\n",
    "                model_dataset = ProductDataset(model_image_dict, transform=transform)\n",
    "                model_dataloader = DataLoader(model_dataset, batch_size=1, shuffle=True)\n",
    "        \n",
    "                model_image, _, model_label, _ = next(iter(model_dataloader))\n",
    "                model_label = model_label[0, 0]\n",
    "                # print(model_label, test_label)\n",
    "        \n",
    "                output_1, output_2 = model(model_image.to(device), test_image.to(device))\n",
    "                euclidean_distance = F.pairwise_distance(output_1, output_2, keepdim=True)\n",
    "        \n",
    "                all_distance.append(euclidean_distance.item())\n",
    "\n",
    "            # Save some pairs of images as visualization\n",
    "            if i % 5 == 0:\n",
    "                # Save inference figure\n",
    "                model_image = np.array(model_image[0].permute(1, 2, 0)*255, dtype=np.uint8)\n",
    "                test_image = np.array(test_image[0].permute(1, 2, 0)*255, dtype=np.uint8)\n",
    "                label_1 = \"good\"\n",
    "                label_2 = \"defect\" if test_label.numpy() == 0 else \"good\"\n",
    "                label = \"same class\" if label_1 == label_2 else \"different class\"\n",
    "                fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "                ax[0].imshow(model_image[:,:,::-1])\n",
    "                ax[0].set_xlabel(label_1, weight = 'bold', fontsize = 20)\n",
    "                #ax[0].axis('off')\n",
    "                ax[1].imshow(test_image[:,:,::-1])\n",
    "                ax[1].set_xlabel(label_2, weight = 'bold', fontsize = 20)\n",
    "                #ax[1].axis('off')\n",
    "                fig.suptitle('Dissimilarity score: ' + str(euclidean_distance.item()))\n",
    "                figure_name = product + '_siamese_' + backbone + '_visualize_' + str(i) + '_embedded_scoring.png'\n",
    "                figure_path = os.path.join(root_path, \n",
    "                        'Figure/visualize_inference/embedded_scoring', product)\n",
    "                if not os.path.exists(figure_path):\n",
    "                    os.mkdir(figure_path)\n",
    "                figure_path = os.path.join(figure_path, figure_name)\n",
    "                fig.savefig(figure_path)\n",
    "\n",
    "                # Save scatter plot\n",
    "                chosen_id = candidate_id_list[0]\n",
    "                label_list = [1 if id != chosen_id else 2 for id in product_embeddings_dict.keys()]\n",
    "                label_list.append(3)\n",
    "                label_name_dict = {1 : 'good', 2 : 'chosen_good', 3 : 'test_image'}\n",
    "                label_name = [label_name_dict[label] for label in label_list]\n",
    "                #print(np.unique(label_dict))\n",
    "                \n",
    "                embedding_list = list(product_embeddings_dict.values())\n",
    "                embedding_list.append(embedding)\n",
    "                embedding_list = np.array(embedding_list)\n",
    "                #print(embedding_list.shape)\n",
    "                embedder = TSNE(2)\n",
    "                embedding_list = embedder.fit_transform(embedding_list)\n",
    "                #print(embedding_list.shape)\n",
    "                \n",
    "                fig, ax = plt.subplots()\n",
    "                scatter = ax.scatter(embedding_list[:,0], embedding_list[:,1], c=label_list, label=label_name)\n",
    "                ax.legend(handles=scatter.legend_elements()[0], labels=list(label_name_dict.values()))#, loc='upper right')\n",
    "                fig.savefig(figure_path[:-4] + '_scatter_plot.png')\n",
    "            \n",
    "            # Calculate average distance between the test sample and all reference images\n",
    "            avg_distance = np.mean(all_distance)\n",
    "            # Keep track of all such distance\n",
    "            all_score.append(np.array([1, int(test_label), 1 == int(test_label), avg_distance]))\n",
    "            # print(avg_distance)\n",
    "            i += 1\n",
    "        # Save the results of all scores to file\n",
    "        result = np.array(all_score)\n",
    "        score_path = os.path.join(root_path, 'result/similarity_scores', product + '_siamese_' + backbone + '_avg_distance.csv')\n",
    "        np.savetxt(score_path, result, delimiter=\",\")\n",
    "        \n",
    "        same_class = result[:,2]\n",
    "        if len(np.unique(same_class)) != 2:\n",
    "            print(np.unique(same_class))\n",
    "        similarity_scores = result[:,3]\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8359dc47-84f5-413e-81d4-62a82c5f7651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.path.dirname(os.getcwd()), 'src'))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import cv2\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "import scipy as sp\n",
    "from utils import *\n",
    "from siamese import *\n",
    "from visualize_attributes import *\n",
    "from sklearn.manifold import TSNE\n",
    "plt.ioff()\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8be5ea16",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = os.path.dirname(os.getcwd())\n",
    "data_path = os.path.join(root_path, \"data/unaugmented_multi_classed_grouped_data\")\n",
    "products = os.listdir(data_path)\n",
    "visualize = True\n",
    "generate_embeddings = False\n",
    "generate_kmeans_labels = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67266744",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans_label(embeddings, save_path, save=False):\n",
    "    # Perform k-means clutering on the embeddings, then save the labels as a new csv\n",
    "    sil_scores = []\n",
    "    # Find the optimal k using silhouette score\n",
    "    for k in range(2, 9):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=0, n_init=\"auto\")\n",
    "        kmeans.fit(embeddings)\n",
    "        label_list = kmeans.labels_\n",
    "        sil_scores.append(silhouette_score(embeddings, label_list, metric='euclidean'))\n",
    "\n",
    "    optimal_k = list(range(2, 9))[np.argmax(sil_scores)]\n",
    "    #print(optimal_k)\n",
    "\n",
    "    # Redo k-means with the found optimal k\n",
    "    kmeans = KMeans(n_clusters=optimal_k, random_state=0, n_init=\"auto\")\n",
    "    kmeans.fit(embeddings)\n",
    "    label_list = kmeans.labels_\n",
    "\n",
    "    # Save the label list as files, use these to calculate mahalonobis distance later\n",
    "    if save:\n",
    "        np.savetxt(save_path, label_list, delimiter=\",\")\n",
    "    return kmeans.labels_\n",
    "\n",
    "\n",
    "def mahalanobis(x=None, data=None, cov=None):\n",
    "    \"\"\"Compute the Mahalanobis Distance between each row of x and the data  \n",
    "    x    : vector or matrix of data with, say, p columns.\n",
    "    data : ndarray of the distribution from which Mahalanobis distance of each observation of x is to be computed.\n",
    "    cov  : covariance matrix (p x p) of the distribution. If None, will be computed from data.\n",
    "    \"\"\"\n",
    "    x_minus_mu = x - np.mean(data)\n",
    "    if not cov:\n",
    "        cov = np.cov(data.T)\n",
    "    inv_covmat = sp.linalg.inv(cov)\n",
    "    left_term = np.dot(x_minus_mu, inv_covmat)\n",
    "    mahal = np.dot(left_term, x_minus_mu.T)\n",
    "    return mahal.diagonal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d5c442f",
   "metadata": {},
   "outputs": [
    {
     "ename": "LinAlgError",
     "evalue": "singular matrix",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m embedding_cluster \u001b[38;5;241m=\u001b[39m product_embeddings[np\u001b[38;5;241m.\u001b[39mwhere(label_list \u001b[38;5;241m==\u001b[39m label)[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Calculate mahalanobis distance from the data point to the cluster\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m distance \u001b[38;5;241m=\u001b[39m \u001b[43mmahalanobis\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_cluster\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(distance)\n",
      "Cell \u001b[0;32mIn[14], line 34\u001b[0m, in \u001b[0;36mmahalanobis\u001b[0;34m(x, data, cov)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cov:\n\u001b[1;32m     33\u001b[0m     cov \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mcov(data\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m---> 34\u001b[0m inv_covmat \u001b[38;5;241m=\u001b[39m \u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcov\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m left_term \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(x_minus_mu, inv_covmat)\n\u001b[1;32m     36\u001b[0m mahal \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(left_term, x_minus_mu\u001b[38;5;241m.\u001b[39mT)\n",
      "File \u001b[0;32m~/Projects/Course/similarity_venv/lib/python3.8/site-packages/scipy/linalg/_basic.py:956\u001b[0m, in \u001b[0;36minv\u001b[0;34m(a, overwrite_a, check_finite)\u001b[0m\n\u001b[1;32m    954\u001b[0m     inv_a, info \u001b[38;5;241m=\u001b[39m getri(lu, piv, lwork\u001b[38;5;241m=\u001b[39mlwork, overwrite_lu\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 956\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msingular matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m info \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124millegal value in \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m-th argument of internal \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    959\u001b[0m                      \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgetrf|getri\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;241m-\u001b[39minfo)\n",
      "\u001b[0;31mLinAlgError\u001b[0m: singular matrix"
     ]
    }
   ],
   "source": [
    "embedding, product_embeddings, label_list\n",
    "# Get all the cluster label available\n",
    "all_labels = np.unique(label_list)\n",
    "# Get the samples corresponding to the label\n",
    "for label in all_labels:\n",
    "    embedding_cluster = product_embeddings[np.where(label_list == label)[0]]\n",
    "    # Calculate mahalanobis distance from the data point to the cluster\n",
    "    distance = mahalanobis(embedding, embedding_cluster)\n",
    "    print(distance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf7110cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------- resnet18 ----------------------------------------------\n",
      "----------------------------------- bottle -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/bottle_siamese_resnet18_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.27it/s]\n"
     ]
    }
   ],
   "source": [
    "for backbone in ['resnet18', 'resnet34', 'resnet50', 'wide_resnet', 'vgg'][:1]:\n",
    "    print('---------------------------------------------- ' + backbone + ' ----------------------------------------------')    \n",
    "    for product in products[:1]:\n",
    "        print('----------------------------------- ' + product + ' -----------------------------------')\n",
    "        # Load corresponding Siamese weights\n",
    "        model_path = os.path.join(root_path, 'models', product + '_siamese_' + backbone + '_subclass_sampling.pth')\n",
    "        if not os.path.exists(model_path):\n",
    "            print('No model for this backbone')\n",
    "            continue\n",
    "        print(model_path)\n",
    "        if backbone in ['wide_resnet', 'vgg11']:\n",
    "            device = 'cpu'\n",
    "\n",
    "        # Load data dicts\n",
    "        product_path = os.path.join(data_path, product)\n",
    "        json_path = os.path.join(root_path, 'data/train_test_split', product)\n",
    "        train_dict = json.load(open(os.path.join(json_path, product + '_train_dict.json'), 'r'))\n",
    "        test_dict = json.load(open(os.path.join(json_path, product + '_test_dict.json'), 'r'))\n",
    "\n",
    "        # Load data informations\n",
    "        good_images_path = [image_path for image_path, label in train_dict.items()\n",
    "                            if label == 1]\n",
    "\n",
    "\n",
    "        # Load the embeddings and the list of id\n",
    "        if generate_embeddings:\n",
    "            product_embeddings, all_idx = map_good_train_samples_to_embeddings(json_path, train_dict, save=True)\n",
    "        else:\n",
    "            score_path = os.path.join(json_path, 'good_embeddings.csv')\n",
    "            product_embeddings =  np.loadtxt(score_path, delimiter=\",\")\n",
    "            all_idx = np.loadtxt(score_path[:-4] + '_id.csv', delimiter=\",\")\n",
    "        product_embeddings_dict = dict(zip(all_idx, product_embeddings))\n",
    "\n",
    "        if generate_kmeans_labels:\n",
    "            save_path = os.path.join(json_path, 'labels.csv')\n",
    "            label_list = kmeans_label(product_embeddings, save_path, save=True)\n",
    "        else:\n",
    "            label_list = np.loadtxt(os.path.join(json_path, 'labels.csv'), delimiter=\",\")\n",
    "\n",
    "        # Prepare embedding model for test data\n",
    "        embedding_model = torchvision.models.resnet50(weights='ResNet50_Weights.DEFAULT')\n",
    "        modules=list(embedding_model.children())[:-1]\n",
    "        embedding_model=nn.Sequential(*modules)\n",
    "        for p in embedding_model.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        # Load data to model\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Resize((1024,1024), antialias=True)])\n",
    "        \n",
    "        all_score = []\n",
    "        i = 0\n",
    "        # Embed the each test image and find its corresponding model images\n",
    "        for image_path in tqdm(list(test_dict.keys())[:1]):\n",
    "            image_dict = {image_path: test_dict[image_path]}\n",
    "\n",
    "            # Load the test images to data loader\n",
    "            embedding_dataset = EmbeddingDataset(image_dict, transform=transform)\n",
    "            embedding_dataloader = DataLoader(embedding_dataset, batch_size=1, shuffle=True)\n",
    "        \n",
    "            # Calculate embedding:\n",
    "            for data, _ in embedding_dataloader:\n",
    "                data = data\n",
    "                embedding = embedding_model(data)\n",
    "            embedding = embedding.squeeze().detach().cpu().numpy()\n",
    "\n",
    "            # Based on mahanalobis distance, firstly find the cluster where the embedding belongs\n",
    "            \n",
    "\n",
    "            # Find the candidate model images based on embedding distance:\n",
    "            top_embeddings = dict(sorted(product_embeddings_dict.items(), \n",
    "                                    key=lambda x: distance(embedding, x[1]))) # Test Mahalanobis distance, check TSNE juan chua \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75db8f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------- resnet18 ----------------------------------------------\n",
      "----------------------------------- bottle -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/bottle_siamese_resnet18_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 50/59 [00:54<00:08,  1.08it/s]/tmp/ipykernel_2656172/595678416.py:116: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`). Consider using `matplotlib.pyplot.close()`.\n",
      "  fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
      "100%|██████████| 59/59 [01:04<00:00,  1.09s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- cable -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/cable_siamese_resnet18_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [01:27<00:00,  1.13s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- capsule -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/capsule_siamese_resnet18_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [01:21<00:00,  1.14s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- carpet -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/carpet_siamese_resnet18_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [01:39<00:00,  1.23s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- grid -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/grid_siamese_resnet18_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [01:15<00:00,  1.07s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- hazelnut -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/hazelnut_siamese_resnet18_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [02:07<00:00,  1.25s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- leather -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/leather_siamese_resnet18_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [01:27<00:00,  1.16s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- metal_nut -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/metal_nut_siamese_resnet18_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [01:17<00:00,  1.14s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- pill -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/pill_siamese_resnet18_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [01:43<00:00,  1.16s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- screw -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/screw_siamese_resnet18_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [01:49<00:00,  1.13s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- tile -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/tile_siamese_resnet18_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [01:21<00:00,  1.15s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- toothbrush -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/toothbrush_siamese_resnet18_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:22<00:00,  1.10s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- transistor -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/transistor_siamese_resnet18_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [01:14<00:00,  1.20s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- wood -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/wood_siamese_resnet18_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:16<00:00,  1.15s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- zipper -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/zipper_siamese_resnet18_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [01:28<00:00,  1.08s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------- resnet34 ----------------------------------------------\n",
      "----------------------------------- bottle -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/bottle_siamese_resnet34_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [01:05<00:00,  1.11s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- cable -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/cable_siamese_resnet34_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 77/77 [01:30<00:00,  1.17s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- capsule -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/capsule_siamese_resnet34_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [01:24<00:00,  1.18s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- carpet -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/carpet_siamese_resnet34_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [01:36<00:00,  1.19s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- grid -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/grid_siamese_resnet34_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [01:16<00:00,  1.08s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- hazelnut -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/hazelnut_siamese_resnet34_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 102/102 [02:04<00:00,  1.22s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- leather -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/leather_siamese_resnet34_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [01:25<00:00,  1.14s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- metal_nut -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/metal_nut_siamese_resnet34_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [01:14<00:00,  1.10s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- pill -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/pill_siamese_resnet34_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 89/89 [01:42<00:00,  1.15s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- screw -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/screw_siamese_resnet34_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 97/97 [01:48<00:00,  1.12s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- tile -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/tile_siamese_resnet34_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [01:21<00:00,  1.14s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- toothbrush -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/toothbrush_siamese_resnet34_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:23<00:00,  1.19s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- transistor -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/transistor_siamese_resnet34_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 62/62 [01:13<00:00,  1.18s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- wood -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/wood_siamese_resnet34_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [01:17<00:00,  1.16s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------- zipper -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/zipper_siamese_resnet34_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [01:30<00:00,  1.11s/it]\n",
      "/tmp/ipykernel_2656172/595678416.py:184: UserWarning: Matplotlib is currently using module://matplotlib_inline.backend_inline, which is a non-GUI backend, so cannot show the figure.\n",
      "  fig.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------- resnet50 ----------------------------------------------\n",
      "----------------------------------- bottle -----------------------------------\n",
      "No model for this backbone\n",
      "----------------------------------- cable -----------------------------------\n",
      "No model for this backbone\n",
      "----------------------------------- capsule -----------------------------------\n",
      "No model for this backbone\n",
      "----------------------------------- carpet -----------------------------------\n",
      "No model for this backbone\n",
      "----------------------------------- grid -----------------------------------\n",
      "No model for this backbone\n",
      "----------------------------------- hazelnut -----------------------------------\n",
      "No model for this backbone\n",
      "----------------------------------- leather -----------------------------------\n",
      "No model for this backbone\n",
      "----------------------------------- metal_nut -----------------------------------\n",
      "/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/models/metal_nut_siamese_resnet50_subclass_sampling.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 1/68 [00:05<06:15,  5.61s/it]\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 9.75 GiB total capacity; 6.17 GiB already allocated; 85.25 MiB free; 6.18 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 103\u001b[0m\n\u001b[1;32m    100\u001b[0m model_label \u001b[38;5;241m=\u001b[39m model_label[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# print(model_label, test_label)\u001b[39;00m\n\u001b[0;32m--> 103\u001b[0m output_1, output_2 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m euclidean_distance \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mpairwise_distance(output_1, output_2, keepdim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    106\u001b[0m all_distance\u001b[38;5;241m.\u001b[39mappend(euclidean_distance\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/Projects/Course/similarity_venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/src/siamese.py:98\u001b[0m, in \u001b[0;36mSiameseNetwork.forward\u001b[0;34m(self, input1, input2)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input1, input2):\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;66;03m# In this function we pass in both images and obtain both vectors\u001b[39;00m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# which are returned\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     output1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_once(input1)\n\u001b[0;32m---> 98\u001b[0m     output2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output1, output2\n",
      "File \u001b[0;32m/media/khoa-ys/Personal/Materials/Master's Thesis/image_similarity_assessment/src/siamese.py:91\u001b[0m, in \u001b[0;36mSiameseNetwork.forward_once\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward_once\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;66;03m# This function will be called for both images\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# Its output is used to determine the similiarity\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/Projects/Course/similarity_venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/Course/similarity_venv/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Projects/Course/similarity_venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/Course/similarity_venv/lib/python3.8/site-packages/torchvision/models/resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Course/similarity_venv/lib/python3.8/site-packages/torchvision/models/resnet.py:274\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    271\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaxpool(x)\n\u001b[1;32m    273\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer1(x)\n\u001b[0;32m--> 274\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    275\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer3(x)\n\u001b[1;32m    276\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer4(x)\n",
      "File \u001b[0;32m~/Projects/Course/similarity_venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/Course/similarity_venv/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Projects/Course/similarity_venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/Course/similarity_venv/lib/python3.8/site-packages/torchvision/models/resnet.py:158\u001b[0m, in \u001b[0;36mBottleneck.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    155\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn3(out)\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdownsample \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     identity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownsample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    160\u001b[0m out \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m identity\n\u001b[1;32m    161\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(out)\n",
      "File \u001b[0;32m~/Projects/Course/similarity_venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/Course/similarity_venv/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Projects/Course/similarity_venv/lib/python3.8/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Projects/Course/similarity_venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/Course/similarity_venv/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    460\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 9.75 GiB total capacity; 6.17 GiB already allocated; 85.25 MiB free; 6.18 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "for backbone in ['resnet18', 'resnet34', 'resnet50', 'wide_resnet', 'vgg'][1:]:\n",
    "    print('---------------------------------------------- ' + backbone + ' ----------------------------------------------')    \n",
    "    for product in products:\n",
    "        print('----------------------------------- ' + product + ' -----------------------------------')\n",
    "        # Load corresponding Siamese weights\n",
    "        model_path = os.path.join(root_path, 'models', product + '_siamese_' + backbone + '_subclass_sampling.pth')\n",
    "        if not os.path.exists(model_path):\n",
    "            print('No model for this backbone')\n",
    "            continue\n",
    "        print(model_path)\n",
    "        if backbone in ['wide_resnet', 'vgg11']:\n",
    "            device = 'cpu'\n",
    "\n",
    "        # Load data dicts\n",
    "        product_path = os.path.join(data_path, product)\n",
    "        json_path = os.path.join(root_path, 'data/train_test_split', product)\n",
    "        train_dict = json.load(open(os.path.join(json_path, product + '_train_dict.json'), 'r'))\n",
    "        test_dict = json.load(open(os.path.join(json_path, product + '_test_dict.json'), 'r'))\n",
    "\n",
    "        # Load data informations\n",
    "        good_images_path = [image_path for image_path, label in train_dict.items()\n",
    "                            if label == 1]\n",
    "\n",
    "\n",
    "        # Load the embeddings and the list of id\n",
    "        if generate_embeddings:\n",
    "            product_embeddings, all_idx = map_good_train_samples_to_embeddings(json_path, train_dict, product, save=True)\n",
    "        else:\n",
    "            score_path = os.path.join(json_path, 'good_embeddings.csv')\n",
    "            product_embeddings =  np.loadtxt(score_path, delimiter=\",\")\n",
    "            all_idx = np.loadtxt(score_path[:-4] + '_id.csv', delimiter=\",\")\n",
    "        product_embeddings_dict = dict(zip(all_idx, product_embeddings))\n",
    "\n",
    "   \n",
    "        # Prepare embedding model for test data\n",
    "        embedding_model = torchvision.models.resnet50(weights='ResNet50_Weights.DEFAULT')\n",
    "        modules=list(embedding_model.children())[:-1]\n",
    "        embedding_model=nn.Sequential(*modules)\n",
    "        for p in embedding_model.parameters():\n",
    "            p.requires_grad = False\n",
    "        \n",
    "        # Load data to model\n",
    "        transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Resize((1024,1024), antialias=True)])\n",
    "        \n",
    "        all_score = []\n",
    "        i = 0\n",
    "        # Embed the each test image and find its corresponding model images\n",
    "        for image_path in tqdm(list(test_dict.keys())):\n",
    "            image_dict = {image_path: test_dict[image_path]}\n",
    "\n",
    "            # Load the test images to data loader\n",
    "            embedding_dataset = EmbeddingDataset(image_dict, transform=transform)\n",
    "            embedding_dataloader = DataLoader(embedding_dataset, batch_size=1, shuffle=True)\n",
    "        \n",
    "            # Calculate embedding:\n",
    "            for data, _ in embedding_dataloader:\n",
    "                data = data\n",
    "                embedding = embedding_model(data)\n",
    "            embedding = embedding.squeeze().detach().cpu().numpy()\n",
    "\n",
    "            # Find the candidate model images based on embedding distance:\n",
    "            top_embeddings = dict(sorted(product_embeddings_dict.items(), \n",
    "                                    key=lambda x: distance(embedding, x[1]))) # Test Mahalanobis distance, check TSNE juan chua \n",
    "            \n",
    "            # Return the dictionary where each key is the test image path and each value are the model images\n",
    "            candidate_id_list = list(top_embeddings.keys())[:1]\n",
    "            candidate_paths = [good_images_path[int(i)] for i in candidate_id_list]\n",
    "            model_image_dict = dict(zip(candidate_paths, [1]*len(candidate_paths)))\n",
    "\n",
    "            # Load the test image to the Siamese dataloader\n",
    "            test_dataset = ProductDataset(image_dict, transform=transform)\n",
    "            test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n",
    "            test_image, _, test_label, _ = next(iter(test_dataloader))\n",
    "            test_label = test_label[0, 0]\n",
    "            \n",
    "            # Perform similarity score assessment with Siamese model\n",
    "            all_distance = []\n",
    "            # Load Siamese model\n",
    "            n_classes = len(np.unique(list(train_dict.values())))\n",
    "            model = SiameseNetwork(n_classes, backbone=backbone)\n",
    "            transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                        transforms.Resize((1024,1024), antialias=True)\n",
    "                                        ])\n",
    "            \n",
    "            model.load_state_dict(torch.load(model_path))\n",
    "            model.eval()\n",
    "            model.to(device)\n",
    "            # Calculate distance from image to all model images\n",
    "            for candidate_path in candidate_paths:\n",
    "                model_image_dict = {candidate_path : 1}\n",
    "                model_dataset = ProductDataset(model_image_dict, transform=transform)\n",
    "                model_dataloader = DataLoader(model_dataset, batch_size=1, shuffle=True)\n",
    "        \n",
    "                model_image, _, model_label, _ = next(iter(model_dataloader))\n",
    "                model_label = model_label[0, 0]\n",
    "                # print(model_label, test_label)\n",
    "        \n",
    "                output_1, output_2 = model(model_image.to(device), test_image.to(device))\n",
    "                euclidean_distance = F.pairwise_distance(output_1, output_2, keepdim=True)\n",
    "        \n",
    "                all_distance.append(euclidean_distance.item())\n",
    "\n",
    "            # Save some pairs of images as visualization\n",
    "            if i % 5 == 0:\n",
    "                # Save inference figure\n",
    "                model_image = np.array(model_image[0].permute(1, 2, 0)*255, dtype=np.uint8)\n",
    "                test_image = np.array(test_image[0].permute(1, 2, 0)*255, dtype=np.uint8)\n",
    "                label_1 = \"good\"\n",
    "                label_2 = \"defect\" if test_label.numpy() == 0 else \"good\"\n",
    "                label = \"same class\" if label_1 == label_2 else \"different class\"\n",
    "                fig, ax = plt.subplots(1, 2, figsize=(10, 5))\n",
    "                ax[0].imshow(model_image[:,:,::-1])\n",
    "                ax[0].set_xlabel(label_1, weight = 'bold', fontsize = 20)\n",
    "                #ax[0].axis('off')\n",
    "                ax[1].imshow(test_image[:,:,::-1])\n",
    "                ax[1].set_xlabel(label_2, weight = 'bold', fontsize = 20)\n",
    "                #ax[1].axis('off')\n",
    "                fig.suptitle('Dissimilarity score: ' + str(euclidean_distance.item()))\n",
    "                figure_name = product + '_siamese_' + backbone + '_visualize_' + str(i) + '_embedded_scoring.png'\n",
    "                figure_path = os.path.join(root_path, \n",
    "                        'Figure/visualize_inference/embedded_scoring', product)\n",
    "                if not os.path.exists(figure_path):\n",
    "                    os.mkdir(figure_path)\n",
    "                figure_path = os.path.join(figure_path, figure_name)\n",
    "                fig.savefig(figure_path)\n",
    "\n",
    "                # Save scatter plot\n",
    "                chosen_id = candidate_id_list[0]\n",
    "                label_list = [1 if id != chosen_id else 2 for id in product_embeddings_dict.keys()]\n",
    "                label_list.append(3)\n",
    "                label_name_dict = {1 : 'good', 2 : 'chosen_good', 3 : 'test_image'}\n",
    "                label_name = [label_name_dict[label] for label in label_list]\n",
    "                #print(np.unique(label_dict))\n",
    "                \n",
    "                embedding_list = list(product_embeddings_dict.values())\n",
    "                embedding_list.append(embedding)\n",
    "                embedding_list = np.array(embedding_list)\n",
    "                #print(embedding_list.shape)\n",
    "                embedder = TSNE(2)\n",
    "                embedding_list = embedder.fit_transform(embedding_list)\n",
    "                #print(embedding_list.shape)\n",
    "                \n",
    "                fig, ax = plt.subplots()\n",
    "                scatter = ax.scatter(embedding_list[:,0], embedding_list[:,1], c=label_list, label=label_name)\n",
    "                ax.legend(handles=scatter.legend_elements()[0], labels=list(label_name_dict.values()))#, loc='upper right')\n",
    "                fig.savefig(figure_path[:-4] + '_scatter_plot.png')\n",
    "            \n",
    "            # Calculate average distance between the test sample and all reference images\n",
    "            avg_distance = np.mean(all_distance)\n",
    "            # Keep track of all such distance\n",
    "            all_score.append(np.array([1, int(test_label), 1 == int(test_label), avg_distance]))\n",
    "            # print(avg_distance)\n",
    "            i += 1\n",
    "        # Save the results of all scores to file\n",
    "        result = np.array(all_score)\n",
    "        score_path = os.path.join(root_path, 'result/similarity_scores', product + '_siamese_' + backbone + '_mahalanobis_distance.csv')\n",
    "        np.savetxt(score_path, result, delimiter=\",\")\n",
    "        \n",
    "        # Visualize similarity score histogram\n",
    "        same_class = result[:,2]\n",
    "        if len(np.unique(same_class)) != 2:\n",
    "            print(np.unique(same_class))\n",
    "        similarity_scores = result[:,3]\n",
    "        \n",
    "        # dissimillar_idx = np.where(same_class == 0.)\n",
    "        # dissimillar_score = similarity_scores[dissimillar_idx]\n",
    "        # simillar_idx = np.where(same_class == 1.)\n",
    "        # simillar_score = similarity_scores[simillar_idx]\n",
    "        # #print(dissimillar_idx, simillar_idx)\n",
    "        # #print(dissimillar_score, simillar_score)\n",
    "        # fig, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "        # ax[0].hist(simillar_score, edgecolor='black',)\n",
    "        #            #bins=np.arange(simillar_score.min(), simillar_score.max(), 0.1))\n",
    "        # ax[0].set_xlabel('Distance', fontsize = 10)\n",
    "        # ax[0].set_ylabel('Number of instance', fontsize = 10)\n",
    "        # ax[0].set_title(product + ': Similarity score distribution for images for GOOD class')\n",
    "        # ax[1].hist(dissimillar_score, edgecolor='black',)\n",
    "        #            #bins=np.arange(dissimillar_score.min(),dissimillar_score.max(), 0.1))\n",
    "        # ax[1].set_xlabel('Distance', fontsize = 10)\n",
    "        # ax[1].set_ylabel('Number of instance', fontsize = 10)\n",
    "        # ax[1].set_title(product + ': Similarity score distribution for images for DEFECT class')\n",
    "        # fig.show()\n",
    "\n",
    "        # figure_name = product + '_siamese_' + backbone + '_similarity_score_distribution' + '_mahalanobis_embedded_scoring.png'\n",
    "        # figure_path = os.path.join(root_path, \n",
    "        #         'Figure/embedded_similarity_score_histogram/' + figure_name)\n",
    "        # fig.savefig(figure_path)\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
